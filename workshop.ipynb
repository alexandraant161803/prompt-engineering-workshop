{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Prompt Engineering with Generative AI\n",
    "Welcome to this workshop on prompt engineering for GenAI! In this session, you'll learn how to write effective prompts that will help you communicate efficiently with large language models like OpenAI's GPT.\n",
    "\n",
    "### Objective: Write a Job Ad for Company X for Position Y.\n",
    "In this exercise, we're going to write a job ad for a specific role at a chosen company. Imagine that you are an HR specialist at Company X, and you need to create an engaging and informative job ad for a position Y.\n",
    "\n",
    "#### Understanding the Prompt Structure\n",
    "We'll use two distinct types of prompts:\n",
    "1. The **System Message**: This sets the stage for the AI, describing its role and how it should behave.\n",
    "2. The **User Message**: This specifies what we are asking the AI to do in the context established by the system message.\n",
    "\n",
    "#### Tips for Effective Prompt Engineering:\n",
    "- Specify the task clearly.\n",
    "- Provide a detailed context to guide the AI.\n",
    "- Be straightforward and unambiguous.\n",
    "- Use examples to illustrate your expectations.\n",
    "- Iterate and refine your prompts based on the AI's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position = \"\"\n",
    "# company =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Define the System Message\n",
    "# This should establish the AI's role and the format in which you expect the response.\n",
    "# Remember that providing an example or template of the desired output can be very beneficial.\n",
    "SYSTEM_MESSAGE: str = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Define the User Message\n",
    "# Ensure this prompt includes the particulars of the job role and any specific details that should be featured in the ad.\n",
    "USER_MESSAGE: str = \"\"\" \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to change anything here. \n",
    "# Function to call Azure OpenAI API with our prompts. \n",
    "async def ask_chatgpt(system_message, user_message) -> str:\n",
    "    # Instantiate the OpenAI client with the necessary details.\n",
    "    client = AsyncAzureOpenAI(\n",
    "        api_key=\"f780dee47b294e5d8f86aa5a1ff1a8a7\",\n",
    "        api_version=\"2023-12-01-preview\",\n",
    "        azure_endpoint=\"https://oai-codepub.openai.azure.com/\",\n",
    "        azure_deployment= \"gpt-35-turbo\"\n",
    "    )\n",
    "\n",
    "    # Send the prompts you have crafted above, to the OpenAI API.\n",
    "    response = await client.chat.completions.create(\n",
    "        temperature=0.5,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # The function returns the content generated by the AI model.\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call the function and obtain our AI-generated job ad.\n",
    "response = await ask_chatgpt(system_message=SYSTEM_MESSAGE, user_message=USER_MESSAGE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing and Refining Outputs\n",
    "Carefully review the job ad generated by the AI.\n",
    "Evaluate its relevance, clarity, and engagement.\n",
    "\n",
    "### Next step - requirements!\n",
    "As a HR specialist at Company X, you just remembered you have the following list of what a job ad needs to contain. Write prompts to ensure the following is in the job ad: \n",
    " - Job Title\n",
    " - Company Description\n",
    " - Responsibilities\n",
    " - Qualifications\n",
    " - Application Process\n",
    " - Name and email of the responsible HR person \n",
    "\n",
    "Remember, prompt engineering is an iterative process. It's normal to go through several revisions before arriving at the most effective prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_MESSSAGE = \"\"\"\n",
    "\"\"\"\n",
    "SYSTEM_MESSAGE = \"\"\" \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call the function and obtain our AI-generated job ad.\n",
    "response = await ask_chatgpt(system_message=SYSTEM_MESSAGE, user_message=USER_MESSAGE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More requirements! \n",
    "Now, we will add another requirement!\n",
    "- The job ad shouldn't be longer than 1900 words. \n",
    "\n",
    "Rewrite your prompts and try to generate a new job ad following this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\"\"\"\n",
    "USER_MESSSAGE = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call the function and obtain our AI-generated job ad.\n",
    "response = await ask_chatgpt(system_message=SYSTEM_MESSAGE, user_message=USER_MESSAGE)\n",
    "print(response)\n",
    "print(\"The length of the job ad is: \" + str(len(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tone and style of the job ad\n",
    "You realize the job ad is a bit boring and you want to rewrite it using a different tone and style! \n",
    "Here are some suggestions of style: \n",
    "- style of a pirate\n",
    "- a comedian\n",
    "- mysterious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USER_MESSSAGE = \"\"\"\"\"\"\n",
    "SYSTEM_MESSAGE = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call the function and obtain our AI-generated job ad.\n",
    "response = await ask_chatgpt(system_message=SYSTEM_MESSAGE, user_message=USER_MESSAGE)\n",
    "print(response)\n",
    "print(\"The length of the job ad is: \" + str(len(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other \"requirements\"/ideas to try: \n",
    "- Write the job ad for a different company culture (e.g., a startup vs. a corporate giant)\n",
    "- Write the job ad for different mediums (e.g., a social media post vs. a formal job board like on LinkedIn).\n",
    "- Make it translate the job ad to another language \n",
    "- Ask it to replace a specific word with an emoji\n",
    "- The output should be in a specific format like JSON.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
